{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkv7iJ1NmPOL",
        "outputId": "0f3851a7-579f-403c-8bf0-81abc0dddab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "import pandas as pd # For handling data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: take text from antivirus_corpus.txt file and save it as dataframe\n",
        "\n",
        "import pandas as pd\n",
        "# Assuming 'antivirus_corpus.txt' is in the current working directory\n",
        "# If not, provide the full path to the file.\n",
        "\n",
        "try:\n",
        "  with open('Antivirus_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "except FileNotFoundError:\n",
        "  print(\"Error: antivirus_corpus.txt not found. Please check the file path.\")\n",
        "  exit()  # Or handle the error appropriately\n",
        "\n",
        "# Create a DataFrame from the text (assuming each line is a document)\n",
        "lines = text.strip().split('\\n')  # Remove leading/trailing whitespace and split into lines\n",
        "data = pd.DataFrame({'text': lines})\n",
        "\n"
      ],
      "metadata": {
        "id": "cWWmvKIBmXNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic preprocessing: lowercase, remove punctuation, and stop words\n",
        "def preprocess(text):\n",
        "   text = text.lower()\n",
        "   text = ''.join(c for c in text if c not in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
        "   stop_words = set(stopwords.words('english'))\n",
        "   words = text.split()\n",
        "   words = [w for w in words if w not in stop_words]\n",
        "   return words"
      ],
      "metadata": {
        "id": "eNM1u-punmXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessor to the text column\n",
        "data['preprocessed_text'] = data['text'].apply(preprocess)\n",
        "\n",
        "#Create a dictionary and corpus:\n",
        "# Create a dictionary from the preprocessed text\n",
        "dictionary = Dictionary(data['preprocessed_text'])"
      ],
      "metadata": {
        "id": "6X4HzD-nn-Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the documents to a sparse corpus representation\n",
        "corpus = [dictionary.doc2bow(text) for text in data['preprocessed_text']]\n",
        "\n",
        "# Train an LDA model with 2 topics\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5)\n",
        "\n",
        "# Print the topics and their associated keywords\n",
        "for i, topic in enumerate(lda_model.print_topics(num_words=5)):\n",
        "  print(f\"Topic {i}: {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ntrL5toPb8",
        "outputId": "a16eba86-7813-448e-91b3-dd1cca5c357f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: (0, '0.013*\"60000\" + 0.012*\"told\" + 0.012*\"owe\" + 0.012*\"crime\" + 0.012*\"scams\"')\n",
            "Topic 1: (1, '0.027*\"toll\" + 0.023*\"year\" + 0.023*\"center\" + 0.023*\"country\" + 0.023*\"people\"')\n",
            "Topic 2: (2, '0.029*\"scam\" + 0.026*\"mcafee\" + 0.023*\"said\" + 0.022*\"toll\" + 0.021*\"grobman\"')\n",
            "Topic 3: (3, '0.029*\"like\" + 0.028*\"texts\" + 0.027*\"may\" + 0.026*\"include\" + 0.026*\"phone\"')\n",
            "Topic 4: (4, '0.016*\"grobman\" + 0.015*\"toll\" + 0.015*\"consumer\" + 0.014*\"mcafee\" + 0.014*\"last\"')\n"
          ]
        }
      ]
    }
  ]
}